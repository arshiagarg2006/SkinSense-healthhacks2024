{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'blue' > Dermnet Classification\n",
        "## <font color= 'blue'> Creating a custom object detection model with YOLO"
      ],
      "metadata": {
        "id": "KkGQgx0S7u0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color = \"blue\"> Imports"
      ],
      "metadata": {
        "id": "i5iMgVz3RcUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display"
      ],
      "metadata": {
        "id": "CkF681Te77RA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "!pip install roboflow\n",
        "!pip install ultralytics\n",
        "!pip install roboflow\n",
        "!pip install tensorflow\n",
        "!pip install torch\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "-_jpkElqX1vc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color = \"blue\"> GPU Check"
      ],
      "metadata": {
        "id": "dPTQXxkhRx2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # making sure GPU is running"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZcmnG4S9LE_",
        "outputId": "d1bb6a70-1d61-4faa-df38-b0a171047c4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 27 14:51:06 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another check to make sure GPU is working\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "numGPUs = len(tf.config.experimental.list_physical_devices('GPU'))\n",
        "print('Num GPUs Available: ', numGPUs)\n",
        "if numGPUs > 0:\n",
        "  print(tf.test.gpu_device_name())\n",
        "  print(device_lib.list_local_devices()[1].physical_device_desc)\n",
        "\n",
        "# check if cuda is available\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  print(\"CUDA is available!\")\n",
        "else:\n",
        "  print(\"CUDA is not available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIC8f1dQ9Ro5",
        "outputId": "ff41be9b-83cd-48d5-e240-dc958728828e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "/device:GPU:0\n",
            "device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "CUDA is available!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'blue'> Load Dermnet Dataset\n",
        "- manually add kaggle.json file (contains api key) to kaggle folder\n",
        "- use kagglehub to download dataset"
      ],
      "metadata": {
        "id": "BsweJrvtUdiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MANUALLY ADD KAGGLE.JSON FILE TO KAGGLE FOLDER\n",
        "\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "kaggle_folder = \"/content/kaggle\"\n",
        "os.makedirs(kaggle_folder)\n",
        "\n",
        "# change current working directory to kaggle folder (kagglehub only downloads in current w directory)\n",
        "os.chdir(kaggle_folder)\n",
        "\n",
        "# download latest version\n",
        "!kaggle datasets download -d shubhamgoel27/dermnet\n",
        "\n",
        "print(\"Current working directory:\", os.getcwd())  # kaggle folder path\n",
        "print(\"Downloaded files:\", os.listdir())  # downloaded data files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei_U8N17mT96",
        "outputId": "3281ad54-76fc-459a-c120-6406fa1db1f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shubhamgoel27/dermnet\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading dermnet.zip to /content/kaggle\n",
            "100% 1.72G/1.72G [00:24<00:00, 99.2MB/s]\n",
            "100% 1.72G/1.72G [00:24<00:00, 77.0MB/s]\n",
            "Current working directory: /content/kaggle\n",
            "Downloaded files: ['dermnet.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip dataset file\n",
        "#dataset_directory = \"/content/kaggle/dermnet\"\n",
        "!unzip dermnet.zip -d dermnet\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "2oq8dZyFp8_b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete classes from train and test folder\n",
        "import shutil\n",
        "train1_delete = \"/content/kaggle/dermnet/train/Tinea Ringworm Candidiasis and other Fungal Infections\"\n",
        "train2_delete = \"/content/kaggle/dermnet/train/Herpes HPV and other STDs Photos\"\n",
        "train3_delete = \"/content/kaggle/dermnet/train/Bullous Disease Photos\"\n",
        "test1_delete = \"/content/kaggle/dermnet/test/Tinea Ringworm Candidiasis and other Fungal Infections\"\n",
        "test2_delete = \"/content/kaggle/dermnet/test/Herpes HPV and other STDs Photos\"\n",
        "test3_delete = \"/content/kaggle/dermnet/test/Bullous Disease Photos\"\n",
        "\n",
        "delete_classes = [train1_delete, train2_delete, train3_delete, test1_delete, test2_delete, test3_delete]\n",
        "\n",
        "for folder_path in delete_classes:\n",
        "# Check if the folder exists\n",
        "\n",
        "  if os.path.exists(folder_path):\n",
        "      # Delete the folder and its contents\n",
        "      shutil.rmtree(folder_path)\n",
        "      print(f\"Folder '{folder_path}' and its contents have been deleted.\")\n",
        "  else:\n",
        "      print(f\"Folder '{folder_path}' does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrqqhGe2rkSO",
        "outputId": "72b02965-2196-4360-aacf-d2eefb5b201f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/kaggle/dermnet/train/Tinea Ringworm Candidiasis and other Fungal Infections' does not exist.\n",
            "Folder '/content/kaggle/dermnet/train/Herpes HPV and other STDs Photos' does not exist.\n",
            "Folder '/content/kaggle/dermnet/train/Bullous Disease Photos' does not exist.\n",
            "Folder '/content/kaggle/dermnet/test/Tinea Ringworm Candidiasis and other Fungal Infections' does not exist.\n",
            "Folder '/content/kaggle/dermnet/test/Herpes HPV and other STDs Photos' does not exist.\n",
            "Folder '/content/kaggle/dermnet/test/Bullous Disease Photos' does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def delete_name_part(directory):\n",
        "    \"\"\"\n",
        "    Parses through folder names in a directory and removes \"photos\" from their names.\n",
        "\n",
        "    Args:\n",
        "        directory: The path to the directory containing the folders.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        if os.path.isdir(os.path.join(directory, filename)):  # check if directory exists\n",
        "            if \"Photos\" in filename:\n",
        "                new_filename = filename.replace(\"Photos\", \"\")\n",
        "                new_filename = new_filename.strip()  # remove leading/trailing spaces\n",
        "                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
        "                print(f\"Renamed '{filename}' to '{new_filename}'\")\n",
        "\n",
        "# Example usage\n",
        "train_directory_path = \"/content/kaggle/dermnet/train\"\n",
        "test_directory_path = \"/content/kaggle/dermnet/test\"\n",
        "delete_name_part(train_directory_path)\n",
        "delete_name_part(test_directory_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je3xXzwDs3iu",
        "outputId": "adf149ce-d5e0-4734-dff1-5c87606e2333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed 'Poison Ivy Photos and other Contact Dermatitis' to 'Poison Ivy  and other Contact Dermatitis'\n",
            "Renamed 'Eczema Photos' to 'Eczema'\n",
            "Renamed 'Hair Loss Photos Alopecia and other Hair Diseases' to 'Hair Loss  Alopecia and other Hair Diseases'\n",
            "Renamed 'Vasculitis Photos' to 'Vasculitis'\n",
            "Renamed 'Acne and Rosacea Photos' to 'Acne and Rosacea'\n",
            "Renamed 'Atopic Dermatitis Photos' to 'Atopic Dermatitis'\n",
            "Renamed 'Poison Ivy Photos and other Contact Dermatitis' to 'Poison Ivy  and other Contact Dermatitis'\n",
            "Renamed 'Eczema Photos' to 'Eczema'\n",
            "Renamed 'Hair Loss Photos Alopecia and other Hair Diseases' to 'Hair Loss  Alopecia and other Hair Diseases'\n",
            "Renamed 'Vasculitis Photos' to 'Vasculitis'\n",
            "Renamed 'Acne and Rosacea Photos' to 'Acne and Rosacea'\n",
            "Renamed 'Atopic Dermatitis Photos' to 'Atopic Dermatitis'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print class names for .yaml file:\n",
        "i = 0\n",
        "\n",
        "for filename in os.listdir(train_directory_path):\n",
        "\n",
        "  if os.path.isdir(os.path.join(train_directory_path, filename)):  # check if directory exists\n",
        "    print(str(i) + \": \", filename)\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIzP7UAZuVKe",
        "outputId": "5c616fbf-5a15-4242-e01b-1e14d6965f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:  Scabies Lyme Disease and other Infestations and Bites\n",
            "1:  Vasculitis\n",
            "2:  Eczema\n",
            "3:  Poison Ivy  and other Contact Dermatitis\n",
            "4:  Warts Molluscum and other Viral Infections\n",
            "5:  Melanoma Skin Cancer Nevi and Moles\n",
            "6:  Lupus and other Connective Tissue diseases\n",
            "7:  Hair Loss  Alopecia and other Hair Diseases\n",
            "8:  Psoriasis pictures Lichen Planus and related diseases\n",
            "9:  Vascular Tumors\n",
            "10:  Light Diseases and Disorders of Pigmentation\n",
            "11:  Cellulitis Impetigo and other Bacterial Infections\n",
            "12:  Seborrheic Keratoses and other Benign Tumors\n",
            "13:  Atopic Dermatitis\n",
            "14:  Urticaria Hives\n",
            "15:  Acne and Rosacea\n",
            "16:  Exanthems and Drug Eruptions\n",
            "17:  Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\n",
            "18:  Nail Fungus and other Nail Disease\n",
            "19:  Systemic Disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# before starting to train model, need to change directory again (back to content folder)\n",
        "# .yaml file is assuming current directory is in content folder --> in .yaml file, referenced val images as test directory\n",
        "# (YAML FILE NOT REQUIRED)\n",
        "\n",
        "# change current working directory to content folder\n",
        "content_folder = \"/content\"\n",
        "os.chdir(content_folder)\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6va0UDPM3Plu",
        "outputId": "9d4452be-9619-4672-e7c2-382e42fd9182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = \"blue\"> Set up Model"
      ],
      "metadata": {
        "id": "zN_jvbRG7Vz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "import ultralytics"
      ],
      "metadata": {
        "id": "A8kXo5If5y1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_config_path = '/content/kaggle/dermnet' # DO NOT HAVE TO USE A .YAML FILE"
      ],
      "metadata": {
        "id": "aN8op7Rz7Pko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = \"blue\"> Benchmark YOLO\n",
        "- 25 imag"
      ],
      "metadata": {
        "id": "0XCAnz_6_3SL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *metrics*\n",
        "**Average Precision (AP)**\n",
        "- computes the area under the precision-recall curve\n",
        "- providing a single value that encapsulates model's precision and recall performance\n",
        "\n",
        "**Mean Average Precision (mAP)**\n",
        "- mAP extends the concept of AP by calculating the average AP values across multiple object classes\n",
        "- useful in multi-class object detection scenarios\n",
        "- provides comprehensive evaluation of model performance\n",
        "\n",
        "**Precision and Recall**\n",
        "- precision quantifies proportion of true positives among all positive predictions, assessing the model's capability to avoid false positives. On the other hand, Recall calculates the proportion of true positives among all actual positives, measuring the model's ability to detect all instances of a class.\n",
        "\n",
        "**F1 Score**\n",
        "- harmonic mean of precision and recall\n",
        "- balanced assessment of a model's performance while considering both false positives and false negatives"
      ],
      "metadata": {
        "id": "oxIDQM_0ceDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucOI-K7dUMrl",
        "outputId": "485dbef3-b74a-4196-f9e6-4467e985c414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Acne and Rosacea',\n",
              " 1: 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions',\n",
              " 2: 'Atopic Dermatitis',\n",
              " 3: 'Cellulitis Impetigo and other Bacterial Infections',\n",
              " 4: 'Eczema',\n",
              " 5: 'Exanthems and Drug Eruptions',\n",
              " 6: 'Hair Loss  Alopecia and other Hair Diseases',\n",
              " 7: 'Light Diseases and Disorders of Pigmentation',\n",
              " 8: 'Lupus and other Connective Tissue diseases',\n",
              " 9: 'Melanoma Skin Cancer Nevi and Moles',\n",
              " 10: 'Nail Fungus and other Nail Disease',\n",
              " 11: 'Poison Ivy  and other Contact Dermatitis',\n",
              " 12: 'Psoriasis pictures Lichen Planus and related diseases',\n",
              " 13: 'Scabies Lyme Disease and other Infestations and Bites',\n",
              " 14: 'Seborrheic Keratoses and other Benign Tumors',\n",
              " 15: 'Systemic Disease',\n",
              " 16: 'Urticaria Hives',\n",
              " 17: 'Vascular Tumors',\n",
              " 18: 'Vasculitis',\n",
              " 19: 'Warts Molluscum and other Viral Infections'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color = 'purple'> train model"
      ],
      "metadata": {
        "id": "oH5YPIQPuM1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "dataset_config_path = '/content/kaggle/dermnet' # DO NOT HAVE TO USE A .YAML FILE\n",
        "model = YOLO('yolov8n-cls.pt') # load a pretrained model\n",
        "model.train(data=dataset_config_path, epochs=10, batch=25) # default images per batch is 16"
      ],
      "metadata": {
        "id": "x7ARfWVHToiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f85419b-477b-4213-94eb-f88024773f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.31M/5.31M [00:00<00:00, 61.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.23 ðŸš€ Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kaggle/dermnet, epochs=10, time=None, patience=100, batch=25, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kaggle/dermnet/train... found 13404 images in 20 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/kaggle/dermnet/test... found 3462 images in 20 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=20\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    355860  ultralytics.nn.modules.head.Classify         [256, 20]                     \n",
            "YOLOv8n-cls summary: 99 layers, 1,463,908 parameters, 1,463,908 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 317MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kaggle/dermnet/train... 13404 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13404/13404 [00:03<00:00, 3643.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kaggle/dermnet/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kaggle/dermnet/test... 3462 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3462/3462 [00:02<00:00, 1368.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kaggle/dermnet/test.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005859375000000001), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.382G      3.069         25        224:   2%|â–         | 9/537 [00:03<02:09,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.382G      3.082         25        224:   3%|â–Ž         | 15/537 [00:04<01:57,  4.43it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 85.4MB/s]\n",
            "       1/10      0.39G      2.569          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:23<00:00,  3.73it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:26<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.351      0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.336G      2.109          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:12<00:00,  4.06it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:24<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.423      0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.338G      1.965          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:17<00:00,  3.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:24<00:00,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.461      0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.338G      1.819          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:13<00:00,  4.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:25<00:00,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.486      0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.338G      1.687          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:12<00:00,  4.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:29<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.515      0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.338G       1.59          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:13<00:00,  4.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:23<00:00,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.53      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.338G      1.493          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:14<00:00,  3.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:22<00:00,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.555      0.861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.338G      1.424          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:16<00:00,  3.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:26<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.559      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.338G       1.36          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:14<00:00,  3.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:25<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.571       0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.338G      1.309          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 537/537 [02:18<00:00,  3.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:23<00:00,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.58      0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.452 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics 8.3.23 ðŸš€ Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1,460,500 parameters, 0 gradients, 3.3 GFLOPs\n",
            "WARNING âš ï¸ Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kaggle/dermnet/train... found 13404 images in 20 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/kaggle/dermnet/test... found 3462 images in 20 classes âœ… \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:25<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.579      0.873\n",
            "Speed: 0.1ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7a99eea1c1c0>\n",
              "curves: []\n",
              "curves_results: []\n",
              "fitness: 0.7258810102939606\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 0.5791450142860413, 'metrics/accuracy_top5': 0.8726170063018799, 'fitness': 0.7258810102939606}\n",
              "save_dir: PosixPath('runs/classify/train')\n",
              "speed: {'preprocess': 0.07188519875070802, 'inference': 0.26055452522000155, 'loss': 0.0003240894954511707, 'postprocess': 0.00028387099452820353}\n",
              "task: 'classify'\n",
              "top1: 0.5791450142860413\n",
              "top5: 0.8726170063018799"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color = 'purple'> download training results"
      ],
      "metadata": {
        "id": "tRDRAih5uBnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download training results\n"
      ],
      "metadata": {
        "id": "EXAkArXIshtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke-Uj-X-qkD0",
        "outputId": "fe30c868-00e7-4b65-ecfc-8b17fa7477bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/runs.zip /content/runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZLmiyOnwz7u",
        "outputId": "98930b5d-769f-45e7-de9b-e73c2cfc44cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/classify/ (stored 0%)\n",
            "  adding: content/runs/classify/train/ (stored 0%)\n",
            "  adding: content/runs/classify/train/results.png (deflated 8%)\n",
            "  adding: content/runs/classify/train/results.csv (deflated 58%)\n",
            "  adding: content/runs/classify/train/confusion_matrix_normalized.png (deflated 10%)\n",
            "  adding: content/runs/classify/train/val_batch2_labels.jpg (deflated 2%)\n",
            "  adding: content/runs/classify/train/val_batch0_pred.jpg (deflated 1%)\n",
            "  adding: content/runs/classify/train/val_batch2_pred.jpg (deflated 2%)\n",
            "  adding: content/runs/classify/train/val_batch1_labels.jpg (deflated 1%)\n",
            "  adding: content/runs/classify/train/train_batch2.jpg (deflated 4%)\n",
            "  adding: content/runs/classify/train/val_batch1_pred.jpg (deflated 1%)\n",
            "  adding: content/runs/classify/train/train_batch1.jpg (deflated 4%)\n",
            "  adding: content/runs/classify/train/events.out.tfevents.1729990135.d67633aadd39.458.0 (deflated 93%)\n",
            "  adding: content/runs/classify/train/val_batch0_labels.jpg (deflated 1%)\n",
            "  adding: content/runs/classify/train/weights/ (stored 0%)\n",
            "  adding: content/runs/classify/train/weights/last.pt (deflated 9%)\n",
            "  adding: content/runs/classify/train/weights/best.pt (deflated 9%)\n",
            "  adding: content/runs/classify/train/confusion_matrix.png (deflated 13%)\n",
            "  adding: content/runs/classify/train/args.yaml (deflated 52%)\n",
            "  adding: content/runs/classify/train/train_batch0.jpg (deflated 3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('runs.zip')\n",
        "files.download('yolo11n.pt')\n",
        "files.download('yolov8n-cls.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_1ySd96mwycR",
        "outputId": "cab7d643-4a2f-4e2e-9b8a-54e6d7a3baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_99ff9ac9-3eb7-435a-b6f0-3cd7e54a54d7\", \"runs.zip\", 8284142)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_268b1270-5dab-4743-99b4-ecebe0e45bd3\", \"yolo11n.pt\", 5613764)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed0bffd5-6a75-4071-90f1-8ed5112f6f82\", \"yolov8n-cls.pt\", 5563076)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color = 'purple'> view training results\n",
        "(receiving error when retrieving; but results were saved in file locally)\n",
        "**maybe try renaming test folder to val folder**"
      ],
      "metadata": {
        "id": "Ax9GFuXYx9uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_results = model.val()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "uD3a6dUtx5gR",
        "outputId": "7c27ebfb-9516-4c82-fb8e-fa4d5b0803f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.23 ðŸš€ Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "WARNING âš ï¸ Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kaggle/dermnet/train... found 13404 images in 20 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/kaggle/dermnet/test... found 3462 images in 20 classes âœ… \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not NoneType",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9e6fbe63eeef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mval\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/validator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m  \u001b[0;31m# used in get_dataloader() for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/classify/val.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m\"\"\"Builds and returns a data loader for classification tasks with given parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/classify/val.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m\"\"\"Creates and returns a ClassificationDataset instance using given image path and preprocessing parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mClassificationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, args, augment, prefix)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# Base class assigned as attribute rather than used as base class to allow for scoping slow torchvision import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mTORCHVISION_0_18\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'allow_empty' argument first introduced in torchvision 0.18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         samples = self.make_dataset(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return make_dataset(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mby\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36mexpanduser\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \"\"\"Expand ~ and ~user constructions.  If user or $HOME is unknown,\n\u001b[1;32m    231\u001b[0m     do nothing.\"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mtilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'~'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color = 'purple'> run validation"
      ],
      "metadata": {
        "id": "hyMxhD3vuTi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#val_metrics = model.val(save_json=True, name=\"val_1\")  # no arguments needed, dataset and settings remembered\n",
        "#print(val_metrics.box.map)  # map\n",
        "#val_metrics.box.maps  # a list contains map50-95 of each category"
      ],
      "metadata": {
        "id": "coYIGe1KmNb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'blue'> Predict"
      ],
      "metadata": {
        "id": "SEQ7L56m-BYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run batched inference on a list of images\n",
        "results = model([\"nailFung1.jpg\"])  # return a list of Results objects\n",
        "print(\"PLEASE = \", results[0].probs.top1)\n",
        "# Process results list\n",
        "#for result in results:\n",
        "    #boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    #masks = result.masks  # Masks object for segmentation masks outputs\n",
        "   # keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "   # probs = result.probs  # Probs object for classification outputs\n",
        "  #  obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "   # result.show()  # display to screen\n",
        "  #  result.save(filename=\"result.jpg\")  # save to disk\n",
        "\n",
        "#pictureClass = model(\"nailFung1.jpg\")\n",
        "\n",
        "\n",
        "\n",
        "  # im1 predictions (pandas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfP2M4Mf-AYX",
        "outputId": "944fc458-95b9-43a6-b72e-532109710c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 224x224 Nail Fungus and other Nail Disease 1.00, Lupus and other Connective Tissue diseases 0.00, Psoriasis pictures Lichen Planus and related diseases 0.00, Warts Molluscum and other Viral Infections 0.00, Vascular Tumors 0.00, 4.1ms\n",
            "Speed: 6.8ms preprocess, 4.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "PLEASE =  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pictureClass)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbt4Z8QtAeWP",
        "outputId": "985feb11-5071-41ab-a5a9-1df75ebbd303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: None\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'Acne and Rosacea', 1: 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 2: 'Atopic Dermatitis', 3: 'Cellulitis Impetigo and other Bacterial Infections', 4: 'Eczema', 5: 'Exanthems and Drug Eruptions', 6: 'Hair Loss  Alopecia and other Hair Diseases', 7: 'Light Diseases and Disorders of Pigmentation', 8: 'Lupus and other Connective Tissue diseases', 9: 'Melanoma Skin Cancer Nevi and Moles', 10: 'Nail Fungus and other Nail Disease', 11: 'Poison Ivy  and other Contact Dermatitis', 12: 'Psoriasis pictures Lichen Planus and related diseases', 13: 'Scabies Lyme Disease and other Infestations and Bites', 14: 'Seborrheic Keratoses and other Benign Tumors', 15: 'Systemic Disease', 16: 'Urticaria Hives', 17: 'Vascular Tumors', 18: 'Vasculitis', 19: 'Warts Molluscum and other Viral Infections'}\n",
            "obb: None\n",
            "orig_img: array([[[ 61,  77, 106],\n",
            "        [ 61,  77, 106],\n",
            "        [ 61,  78, 105],\n",
            "        ...,\n",
            "        [ 56,  43,  21],\n",
            "        [ 56,  43,  21],\n",
            "        [ 58,  45,  23]],\n",
            "\n",
            "       [[ 61,  77, 106],\n",
            "        [ 61,  77, 106],\n",
            "        [ 61,  78, 105],\n",
            "        ...,\n",
            "        [ 57,  42,  23],\n",
            "        [ 56,  42,  24],\n",
            "        [ 58,  44,  26]],\n",
            "\n",
            "       [[ 61,  77, 106],\n",
            "        [ 61,  77, 106],\n",
            "        [ 61,  78, 105],\n",
            "        ...,\n",
            "        [ 56,  40,  23],\n",
            "        [ 56,  42,  24],\n",
            "        [ 58,  44,  26]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 70,  83, 105],\n",
            "        [ 70,  83, 105],\n",
            "        [ 70,  83, 105],\n",
            "        ...,\n",
            "        [ 24,  18,  13],\n",
            "        [ 24,  18,  13],\n",
            "        [ 24,  18,  13]],\n",
            "\n",
            "       [[ 70,  83, 105],\n",
            "        [ 70,  83, 105],\n",
            "        [ 70,  83, 105],\n",
            "        ...,\n",
            "        [ 24,  18,  13],\n",
            "        [ 24,  18,  13],\n",
            "        [ 24,  18,  13]],\n",
            "\n",
            "       [[ 70,  83, 105],\n",
            "        [ 70,  83, 105],\n",
            "        [ 70,  83, 105],\n",
            "        ...,\n",
            "        [ 24,  18,  13],\n",
            "        [ 24,  18,  13],\n",
            "        [ 24,  18,  13]]], dtype=uint8)\n",
            "orig_shape: (437, 810)\n",
            "path: '/content/nailFung1.jpg'\n",
            "probs: ultralytics.engine.results.Probs object\n",
            "save_dir: 'runs/classify/train11'\n",
            "speed: {'preprocess': 8.9111328125, 'inference': 3.830432891845703, 'postprocess': 0.06413459777832031}]\n"
          ]
        }
      ]
    }
  ]
}